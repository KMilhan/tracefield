# ISO/IEC/IEEE 42010

## GuideCam Telemetry 기반 Imaging 파이프라인 아키텍처

본 문서는 ISO/IEC/IEEE 42010 표준에 따라, 아마추어 천체사진 환경에서 **Primary 가이딩**, **Secondary 가이드캠 텔레메트리**, **메인 이미징**을 결합한 데이터 파이프라인의 아키텍처를 기술한다. 특히 **Ekos 노출 시작/종료 트리거**를 활용하여 시간 동기화 복잡도를 최소화하는 설계를 명시한다.

---

## 1. Introduction

### 1.1 Purpose

이 아키텍처의 목적은 다음과 같다.

* PSF 왜곡의 원인을 결과 이미지 이후가 아닌 **관측 시점의 텔레메트리 차원**에서 분해
* 프레임 제거 중심의 워크플로를 **가중치 기반 스택**으로 전환
* 후처리 단계(BXT 등)의 과잉 해석 가능성을 사전에 억제
* 구현 복잡도를 최소화하면서도 미래 재해석 가능성을 최대화

### 1.2 Scope

본 문서는 다음을 다룬다.

* Ekos 기반 촬영 환경
* PHD2 가이딩 로그 활용
* Secondary 가이드캠 영상 저장 전용 운용
* 서브 노출 단위 품질 평가 및 가중치 스택

광학 설계, 카메라 하드웨어 세부, 개별 알고리즘 구현은 범위에서 제외한다.

---

## 2. Stakeholders and Concerns

### 2.1 Stakeholders

* Observer: 천체사진 촬영자
* System Architect: 파이프라인 설계 및 유지 주체
* Post-processing Operator: PixInsight 등 후처리 수행자
* Future Self: 과거 데이터의 재해석을 수행하는 동일 사용자

### 2.2 Concerns

* 왜 특정 서브가 PSF를 왜곡하는지 설명 가능성
* 후처리 결과의 재현성과 납득 가능성
* 데이터 저장·동기화 복잡도의 관리
* 장비·소프트웨어 변경 시 파이프라인 유지성

---

## 3. System Context

본 시스템은 다음 외부 시스템과 상호작용한다.

* Ekos Imaging Scheduler
* PHD2 Guiding System
* Primary Imaging Camera
* Primary Guide Camera (가이딩 전용)
* Secondary Guide Camera (텔레메트리 전용)
* Post-processing Environment (PixInsight)

Ekos는 **노출 시작/종료 이벤트의 단일 진실 원천(single source of truth)** 역할을 한다.

---

## 4. Architectural Drivers

### 4.1 Key Drivers

* 단순성: 시간 동기화 문제를 ms 정밀도가 아닌 서브 단위 문제로 축소
* 관측 가능성: 가이딩 루프에서 버려지는 고주파 사건을 별도 센서로 확보
* 설명 가능성: 픽셀 피핑 단계에서 결과를 원인으로 설명 가능해야 함

### 4.2 Constraints

* 노출 시작 시각의 절대적 정확성은 확보 불가
* 야외 랩탑 환경에서 실시간 운용 가능해야 함
* 사용자 개입 없이 자동 동작해야 함

---

## 5. Architecture Description

### 5.1 Components

#### 5.1.1 Primary Imaging Subsystem

* 메인 카메라
* Ekos에 의해 제어됨
* FITS 서브 생성

#### 5.1.2 Primary Guiding Subsystem

* PHD2
* Primary Guide Camera
* 저주파 motion 제어 및 로그 생성

#### 5.1.3 Secondary Telemetry Subsystem

* Secondary Guide Camera
* 별도 광학계 사용
* 가이딩에는 관여하지 않음
* 영상 저장 전용

#### 5.1.4 Control and Trigger Subsystem

* Ekos 노출 이벤트
* 노출 시작 시 Secondary 영상 녹화 시작
* 노출 종료 시 Secondary 영상 녹화 종료
* 전후 가드 밴드 허용

---

### 5.2 Data Flows

1. Ekos가 노출 시작 이벤트 발생
2. Secondary Telemetry Subsystem이 영상 녹화 시작
3. Primary Imaging Subsystem이 서브 노출 수행
4. PHD2가 가이딩 로그 지속 기록
5. Ekos가 노출 종료 이벤트 발생
6. Secondary Telemetry Subsystem이 영상 녹화 종료
7. 세 데이터 소스가 동일 서브 ID로 묶임

---

## 6. Time Synchronization Strategy

### 6.1 Design Principle

* 정확한 셔터 오픈 시각을 알 수 없다는 사실을 전제로 설계
* 노출 구간을 **넉넉히 감싸는 창(window)** 만으로 충분하다고 판단

### 6.2 Implementation

* Ekos 노출 시작 이벤트: 녹화 시작 트리거
* Ekos 노출 종료 이벤트: 녹화 종료 트리거
* 전후 수 초의 여분 데이터 허용

이 전략은 디더링, 다운로드 지연, OS 스케줄링 변수를 자연스럽게 흡수한다.

---

## 7. Viewpoints and Views

### 7.1 Data View

본 아키텍처에서 다루는 데이터는 세 가지 서로 다른 시간·의미 스케일을 갖는 축으로 구성된다.

* 메인 FITS 서브: 결과 이미지 차원

    * 노출 단위 데이터
    * seeing, motion, optics가 혼합된 최종 결과

* PHD2 로그: 저주파 제어 차원

    * 가이딩 샘플 단위(약 0.5~2초)
    * 제어 가능한 motion 성분 중심

* Secondary 가이드캠 영상: 고주파 관측 차원

    * 프레임 단위(5~20Hz)
    * 제어 루프에서 평균·무시되는 고주파 motion 및 seeing tip–tilt 기록

이 세 데이터는 **정밀 시간 일치가 아닌, 서브 단위 느슨한 동기화**를 통해 결합된다.

---

### 7.2 Processing View

Processing View는 본 아키텍처의 핵심이며, 단순한 이미지 처리 파이프라인이 아니라 **원인 기반 품질 평가 흐름**을 기술한다.

#### 7.2.1 서브 구간 동기화

* Ekos 노출 시작 이벤트를 기준으로 Secondary 영상 녹화 시작
* Ekos 노출 종료 이벤트를 기준으로 Secondary 영상 녹화 종료
* 전후 수 초의 가드 밴드를 포함하여 서브 구간을 느슨하게 감쌈

이 단계의 목적은 ms 단위 정렬이 아니라, **각 서브에 대응되는 관측 창(window)을 정의**하는 것이다.

---

#### 7.2.2 서브 단위 메트릭 추출

각 서브에 대해 다음 세 계열의 메트릭을 생성한다.

**A. 메인 이미지 기반 메트릭(결과 지표)**

* FWHM
* eccentricity
* star count
* SNR

이 지표는 서브 품질의 결과적 표현이며, 원인 분해에는 한계가 있다.

**B. PHD2 기반 메트릭(저주파 제어 지표)**

* RMS guiding error
* peak-to-peak error
* dither/settle 구간 영향량

이 지표는 제어 루프가 감지한 motion의 크기를 나타낸다.

**C. Secondary 기반 메트릭(고주파 관측 지표)**

* centroid dx, dy의 고주파 에너지
* peak excursion 이벤트 빈도
* FWHM burst 발생 빈도
* 멀티스타일 경우 스타 간 centroid 분산 및 공분산

이 지표는 motion blur 성분과 seeing tip–tilt 성분을 가장 직접적으로 반영한다.

---

#### 7.2.3 품질 해석 계층

메트릭은 단순 비교가 아니라, 다음 질문에 답하는 데 사용된다.

* 이 서브의 PSF 왜곡은 주로 motion인가, seeing인가?
* 왜 특정 서브가 평균 PSF를 찢는가?
* 이 서브는 제거 대상인가, 가중치 감소 대상인가?

이 계층은 **이진 판단을 피하고 연속적 책임 분산**을 목표로 한다.

---

#### 7.2.4 가중치 계산 및 스택

서브 제거 대신, 각 서브는 연속 가중치로 스택에 기여한다.

* 가중치 함수 예:

  weight = f(
  main_image_quality,
  phd2_stability,
  secondary_high_freq_stability
  )

이 접근은:

* 특정 서브가 평균 PSF를 왜곡하는 현상을 억제
* 필드 전반의 PSF 분산 감소
* 후속 복원 단계의 입력 안정화

을 목표로 한다.

---

#### 7.2.5 후처리 단계 연계

가중치 스택 이후 처리 흐름은 다음과 같다.

1. LN(LocalNormalization)

    * 배경 레벨 및 그라디언트 정합
    * 광도 불일치 억제

2. BXT(BlurXTerminator 등 복원 단계)

    * motion 성분이 과도하게 섞이지 않은 입력 사용
    * 과잉 해석 및 인위적 고주파 구조 발생 가능성 감소

이 단계에서의 목표는 **더 공격적인 복원**이 아니라, **덜 틀리는 복원**이다.

---

#### 7.2.6 픽셀 피핑 기반 검증 루프

최종 검증은 다음 관점에서 수행된다.

* 확대 시 설명 불가능한 방향성 구조가 줄었는가
* 별 코어 형태가 필드 전반에서 일관적인가
* 특정 서브의 흔적이 국소적으로 남지 않는가

검증 결과는 가중치 함수 조정으로만 피드백되며, 아키텍처 자체는 변경하지 않는다.

---

## 8. Rationale and Trade-offs

### 8.1 Rationale

* 프레임 단위 정밀 동기화는 목적 대비 과잉
* Ekos 트리거는 가장 단순하고 신뢰 가능한 경계 제공
* Secondary 센서를 제어 루프에서 분리함으로써 안정성 확보

### 8.2 Trade-offs

* ms 단위 사건의 정확한 위치 정보는 포기
* 대신 서브 품질 평가의 신뢰도와 재현성 확보

---

## 9. Consequences

* 후처리 단계에서 과도한 파라미터 조정 필요 감소
* 픽셀 피핑 시 설명 불가능한 구조 감소
* 데이터 용량 증가는 허용 가능한 비용으로 전환
* 미래 분석 요구 변화에 대한 높은 적응성

---

## 10. Failure Modes and Limitations

본 섹션은 본 아키텍처가 **의도적으로 수용하는 실패 모드**와 **설계 범위 밖의 한계**를 명시한다. 이는 시스템이 언제, 왜, 어떻게 "틀릴 수 있는지"를 사전에 고정하여, 구현 단계에서의 과도한 복잡도 증가를 방지하기 위함이다.

---

### 10.1 시간 정렬 오차

* Ekos 노출 시작/종료 트리거는 셔터의 실제 개폐 시각과 정확히 일치하지 않을 수 있음
* Secondary 영상에는 노출과 무관한 구간(디더링, settle, 다운로드 지연)이 포함될 수 있음

**수용 이유**:

* 본 설계의 목적은 ms 단위 사건 복원이 아니라 서브 품질의 통계적 평가임
* 경계 오차는 가중치를 보수적으로 낮추는 방향으로 작용하며, 픽셀 피핑 안정성에는 유리함

---

### 10.2 고주파 사건의 위치 불확정성

* Secondary 텔레메트리에서 관측된 고주파 motion 또는 seeing burst가
  서브 내부 정확히 어느 시점에 발생했는지는 알 수 없을 수 있음

**수용 이유**:

* 후처리 안정화 관점에서는 사건의 정확한 시점보다
  "그 서브에 그런 사건이 있었는가"가 중요함

---

### 10.3 광경로 차이에 따른 불일치

* Secondary 가이드캠은 메인 이미징 광경로와 다를 수 있음
* 이에 따라 일부 motion/seeing 성분이 메인 이미지와 완전히 동일하게 투영되지 않을 수 있음

**수용 이유**:

* 본 설계는 절대적 PSF 복원을 목표로 하지 않음
* 원인 분해의 신뢰도 향상(seeing vs motion 구분)이 주 목적임

---

### 10.4 가중치 함수의 경험적 성격

* 서브 가중치는 경험적 함수로 설계됨
* 특정 조건에서 최적이 아닐 수 있음

**완화 전략**:

* 가중치 함수는 파이프라인 외부에서 독립적으로 조정 가능
* 아키텍처 자체는 변경하지 않음

---

### 10.5 저장 데이터의 과잉

* Secondary 영상 전체 저장은 대용량 데이터를 생성함

**수용 이유**:

* 저장 비용이 상대적으로 저렴한 환경을 전제로 함
* 미래 재해석 가능성을 우선함

---

## 11. Data Storage and Recording Considerations

본 섹션은 영상 저장 포맷 및 기록 전략에 대한 **아키텍처 수준의 고려사항**을 기술한다. 특정 포맷을 강제하지 않으며, 구현 세부는 ADR로 분리 가능하다.

---

### 11.1 Secondary 영상 기록 원칙

* 가이딩 제어에 영향을 주지 않아야 함
* 실시간 분석을 요구하지 않음
* 기록된 영상은 사후 해석 가능성이 우선됨

---

### 11.2 영상 포맷에 대한 요구사항(비구속적)

Secondary 영상 포맷은 다음 요구를 만족해야 한다.

* 프레임 순서 보존
* 프레임 드롭 발생 시 감지 가능
* 가능하다면 프레임별 타임스탬프 보존
* 손실 압축의 경우, centroid/FWHM 추정이 가능할 정도의 정량성 유지

이 요구사항을 만족한다면:

* 무손실 포맷
* 손실 영상 포맷
* 스트리밍 컨테이너

모두 허용된다.

---

### 11.3 스트레치 및 손실 압축의 허용

* Secondary 영상은 인간 관측용이 아님
* 신호는 저차 motion 및 형태 지표에 한정됨

따라서:

* 고정 스트레치 후 8bit 변환
* 일반 영상 코덱(H.264/H.265/AV1 등)

은 **아키텍처적으로 허용**된다.

단, 이 경우에도:

* 서브 품질 메트릭은 원본 프레임 또는 무손실 단계에서 추출되어야 함

---

### 11.4 메타데이터 연계

* Secondary 영상은 서브 ID 또는 Ekos 노출 ID와 연계되어야 함
* 파일명, sidecar, 컨테이너 메타데이터 중 방식은 제한하지 않음

---

## 12. Summary

본 아키텍처는 실패 가능성과 한계를 명시적으로 수용함으로써, 구현 단계에서 불필요한 정밀도 경쟁과 복잡도 폭증을 방지한다.

Secondary 텔레메트리는 절대적 복원 수단이 아니라, 서브 품질 평가와 후처리 입력 안정화를 위한 관측 보조 축이며, 영상 저장 포맷 및 기록 방식은 이 목적을 저해하지 않는 범위 내에서 자유롭게 선택될 수 있다.
